\chapter{Introduction}%
\label{intro}

Recently, there has been a revival in the usage of deep
learning\cite{lecun2015deep} techniques, allowing for large advances across
a number of fields including image recognition\cite{krizhevsky2012imagenet},
speech recognition\cite{graves2013speech, hinton2012deep}. Similarly,
there has been recent advancements in the area of reinforcement learning,
where intelligent agents have been able to complete tasks that were once thought
to be too complex for an agent to complete, such as beating humans in the game
Go\cite{silver2016mastering} and more generally such as across a wide range of
Atari 2600 games\cite{mnih2015human}. However, despite these recent advancements,
there are still a number of challenges that prove difficult for current
reinforcement learning algorithms.

This has lead DeepMind\cite{deepmind} to developing the
StarCraft II Learning Environment\cite{vinyals2017starcraft}, a Python
environment for interfacing with the game StarCraft II\cite{pysc2, starcraft2}.
This game was chosen as it involves a number of areas that current reinforcement
learning algorithms struggle with, including partial observation, a large action
space, control of multiple units and the reward is delayed across thousands of
steps, meaning the agent needs to use long-term strategies.

This environment was developed to be used as a test bed for both new learning
techniques, as well as the improvement of new learning techniques. An agent
that is able to intelligently play the mini-games and the full game of
StarCraft II would need to act very intelligently, which has lead to the large amount
of research into the area, both specifically for StarCraft II and broadly for
reinforcement learning.

\section{Aim}

\section{Objectives}

% Objectives
\begin{enumerate}
    \item
\end{enumerate}

% Deliverables based on the Objectives
\begin{enumerate}
    \item
\end{enumerate}

\section{Scope}

\section{Report Structure}
