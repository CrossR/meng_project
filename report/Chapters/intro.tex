\chapter{Introduction}%
\label{intro}

Recently, there has been a revival in the usage of deep
learning\cite{lecun2015deep} techniques, allowing for large advances across
a number of fields including image recognition\cite{krizhevsky2012imagenet},
speech recognition\cite{graves2013speech, hinton2012deep}. Similarly,
there has been recent advancements in the area of reinforcement learning,
where intelligent agents have been able to complete tasks that were once thought
to be too complex for an agent to complete, such as beating humans in the game
Go\cite{silver2016mastering} and more generally such as across a wide range of
Atari 2600 games\cite{mnih2015human}. However, despite these recent advancements,
there are still a number of challenges that prove difficult for current
reinforcement learning algorithms.

This has lead DeepMind\cite{deepmind} to developing the
StarCraft II Learning Environment\cite{vinyals2017starcraft}, a Python
environment for interfacing with the game StarCraft II\cite{pysc2, starcraft2}.
This game was chosen as it involves a number of areas that current reinforcement
learning algorithms struggle with, including partial observation, a large action
space, control of multiple units and the reward is delayed across thousands of
steps, meaning the agent needs to use long-term strategies.

This environment was developed to be used as a test bed for both new learning
techniques, as well as the improvement of new learning techniques. An agent
that is able to intelligently play the mini-games and the full game of
StarCraft II would need to act very intelligently, which has lead to the large
amount of research into the area, both specifically for StarCraft II and
broadly for reinforcement learning.

\section{Aim}

This project aims to prototype an agent that is able to exhibit intelligent
behaviour in the game of StarCraft II\@ (SC2). This will be achieved using
reinforcement learning (RL), that is without using any form of supervised
learning method.

With the recent addition of the StarCraft II Learning Environment (SC2LE),
applying reinforcement learning techniques and similar to SC2 has become
much easier. With the use of SC2LE, the major aspects of the game are
delivered using an easier to use API, rather than having to read the
screen's state using the pixel values. This, along with an input API,
mean that the creating agents on top of SC2 is much easier.

Specifically, this project aims to apply interesting techniques such as
transfer and curriculum learning to the problems defined in the SC2LE\@.
This has interesting research potential and the chance to be very effective
due to the increasing complexity of the challenge mini-games that are defined
in the SC2LE\@.

\section{Objectives}

As the project is broadly very experimental, there is a few objectives that
have been defined, as well as associated deliverables, which are:

\begin{enumerate}
    \item The understanding and clear definition of the project space, that is
        what techniques will be used to tackle the problems, as well as
        metrics to measure the performance of a given prototype.
    \item A prototype (or multiple using various techniques) that exhibit
        intelligent behaviour in some behaviour in a given scenario for
        the game StarCraft II\@.
    \item Performance analysis of the given prototypes, such that their
        effectiveness can be measured and compared to other solutions, both of
        our design and as defined in other papers.
\end{enumerate}

In turn, these objectives lead to the following deliverable:

\begin{enumerate}
    \item A Git repository containing the prototypes and any other associated
        code in getting the agents running.
    \item Associated learnt weights for each of the given agents, such that
        their performance can be easily tested without having to retrain
        the network.
    \item The evaluation of each of the given agents, along side a full report
        detailing the rest of the project.
\end{enumerate}

\section{Scope}

\section{Report Structure}
