\chapter{Research}%
\label{research}

\section{Theory}
% Brief explanation of why we needed to do so much research, as well
% as why it is so important for our style of project
% i.e. Exploratory Software

\subsection{StarCraft II}
% What is StarCraft II?

% Issues with StarCraft II
% Potentially, some of this can be moved to the implementation
% chapter too.
A game of StarCraft II includes many challenges for a player in terms of complexity.
The game state can be comprised of thousands of different aspects that could represent
important information for the player. In order for the agent to be able to act,
it must be given an input, stimulus of some form, to evaluate and proceed with
taking an action. This makes the game ideal for an unsupervised learning environment.
The environment is broken into states.

Each state represents information about the game at a given moment.
This is then fed into the neural network and returns a value outcome of what the
optimal action to be taken would be.
A different approach would be to use a Q-learning algorithm with a table format for
storing actions and values.
The main difficulty would be the size of the given table.
As more actions are introduced the size of the table would increase and new values would
need to be optimized for the given cells.
Using a neural network, this issue can be avoided by simply adding new weights and
nodes to the network.

\subsection{Q-Learning Table}

\subsection{Deep Q Networks}

\subsection{Neural Networks}

\subsection{Convolutional Neural Networks}

\section{Challenges}
% Add more info here about the tech and the challenges it faces
% i.e. the problems in Reinforcement Learning as a whole

\section{Reinforcement Learning For Games}
% The earlier sections should cover the general tech,
% whereas this section will talk about it applied to games
% and the unique problems that raises.

\section{Existing Methods}
% This should then move on from the previous section
% to show how the outlined challenges are dealt with.

\section{Conclusion}

