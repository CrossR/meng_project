This project aims to explore how different learning techniques affect an agents
learning efficiency across many tasks in the game StarCraft II\@.
This will involve the use of a few different types of learning for the agent,
including transfer learning and curriculum learning. The hope is that the
agent will not only be able to exhibit intelligent behaviour on the cut-down
mini-games of StarCraft II, but also be able to move between them efficiently
while reusing the same network.

This project will use the StarCraft II Learning Environment written by DeepMind,
along with TensorFlow and different styles of neural networks to program the agents.

This work was undertaken on ARC3, part of the High Performance Computing
facilities at the University of Leeds, UK\@.
