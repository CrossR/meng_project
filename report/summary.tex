This project aims to explore how different learning techniques affect an agents
learning efficiency across a number of different tasks in the game StarCraft II\@.
This will involve the use of a few different types on learning for the agent,
including transfer learning and curriculum learning. The hope is that the
agent will not only be able to exhibit intelligent behaviour on the cut down
mini-games of StarCraft II, but also be able to effectively move between them
whilst reusing the same network, or parts of them.

This project will use the StarCraft II Learning Environment written by DeepMind,
along with TensorFlow and different styles of neural networks to program the agents.
